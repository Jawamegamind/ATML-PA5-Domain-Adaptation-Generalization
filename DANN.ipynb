{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading in the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torchvision.datasets import MNIST, USPS, SVHN\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.autograd import Function\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is:  cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"The device is: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a subset\n",
    "def create_subset(dataset, subset_size, seed=42):\n",
    "    \"\"\"\n",
    "    Creates a random subset of the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (Dataset): The original dataset.\n",
    "        subset_size (int): The number of samples in the subset.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        Subset: A PyTorch Subset object.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    indices = random.sample(range(len(dataset)), subset_size)\n",
    "    return Subset(dataset, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Office-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_path: OFFICE31/amazon\n",
      "webcam_path: OFFICE31/webcam\n",
      "dslr_path: OFFICE31/dslr\n",
      "amazon_loader size: 45\n",
      "webcam_loader size: 12\n",
      "dslr_loader size: 7\n"
     ]
    }
   ],
   "source": [
    "data_path = 'OFFICE31'\n",
    "amazon_path = os.path.join(data_path, 'amazon')\n",
    "webcam_path = os.path.join(data_path, 'webcam')\n",
    "dslr_path = os.path.join(data_path, 'dslr')\n",
    "\n",
    "print('amazon_path:', amazon_path)\n",
    "print('webcam_path:', webcam_path)\n",
    "print('dslr_path:', dslr_path)\n",
    "\n",
    "def load_data(root_path, domain, batch_size, phase):\n",
    "    transform_dict = {\n",
    "        'src': transforms.Compose(\n",
    "        [transforms.RandomResizedCrop(224),\n",
    "         transforms.RandomHorizontalFlip(),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225]),\n",
    "         ]),\n",
    "        'tar': transforms.Compose(\n",
    "        [transforms.Resize(224),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225]),\n",
    "         ])}\n",
    "    data = datasets.ImageFolder(root=os.path.join(root_path, domain), transform=transform_dict[phase])\n",
    "    data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=phase=='src', drop_last=phase=='tar', num_workers=8)\n",
    "    return data_loader\n",
    "\n",
    "amazon_loader = load_data(data_path, 'amazon', 64, 'src')\n",
    "webcam_loader = load_data(data_path, 'webcam', 64, 'tar')\n",
    "dslr_loader = load_data(data_path, 'dslr', 64, 'tar')\n",
    "\n",
    "# Checking the size of these data loaders\n",
    "print('amazon_loader size:', len(amazon_loader))\n",
    "print('webcam_loader size:', len(webcam_loader))\n",
    "print('dslr_loader size:', len(dslr_loader))\n",
    "\n",
    "# # Check the size of the first batch\n",
    "# amazon_data = next(iter(amazon_loader))\n",
    "# webcam_data = next(iter(webcam_loader))\n",
    "# dslr_data = next(iter(dslr_loader))\n",
    "\n",
    "# print('amazon_data size:', amazon_data[0].size())\n",
    "# print('webcam_data size:', webcam_data[0].size())\n",
    "# print('dslr_data size:', dslr_data[0].size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digits Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n",
      "MNIST Train Size: 60000\n",
      "MNIST Test Size: 10000\n",
      "USPS Train Size: 7291\n",
      "USPS Test Size: 2007\n",
      "SVHN Train Size: 73257\n",
      "SVHN Test Size: 26032\n"
     ]
    }
   ],
   "source": [
    "# Define transformations for the datasets\n",
    "transform_mnist_usps = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),                  # Resize to 224x224\n",
    "    transforms.Grayscale(num_output_channels=3),  # Ensure grayscale images (for USPS/MNIST) and convert to 3 channels\n",
    "    transforms.ToTensor(),                        # Convert to Tensor\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "    # transforms.Normalize((0.5,), (0.5,))          # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "transform_svhn = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),                  # Resize to 224x224\n",
    "    transforms.ToTensor(),                        # Convert to Tensor\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "    # transforms.Normalize((0.5,), (0.5,))          # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Loading in MNIST dataset\n",
    "mnist_train = MNIST(root='./data', train=True, download=True, transform=transform_mnist_usps)\n",
    "mnist_test = MNIST(root='./data', train=False, download=True, transform=transform_mnist_usps)\n",
    "\n",
    "# MNIST dataloaders\n",
    "mnist_train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "mnist_test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "# Loading in the USPS dataset\n",
    "usps_train = USPS(root='./data', train=True, download=True, transform=transform_mnist_usps)\n",
    "usps_test = USPS(root='./data', train=False, download=True, transform=transform_mnist_usps)\n",
    "\n",
    "# USPS dataloaders\n",
    "usps_train_loader = DataLoader(usps_train, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "usps_test_loader = DataLoader(usps_test, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "# Loading in the SVHN dataset\n",
    "svhn_train = SVHN(root='./data', split='train', download=True, transform=transform_svhn)\n",
    "svhn_test = SVHN(root='./data', split='test', download=True, transform=transform_svhn)\n",
    "\n",
    "# SVHN dataloaders\n",
    "svhn_train_loader = DataLoader(svhn_train, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "svhn_test_loader = DataLoader(svhn_test, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "# Print dataset sizes for verification\n",
    "print(f\"MNIST Train Size: {len(mnist_train)}\")\n",
    "print(f\"MNIST Test Size: {len(mnist_test)}\")\n",
    "print(f\"USPS Train Size: {len(usps_train)}\")\n",
    "print(f\"USPS Test Size: {len(usps_test)}\")\n",
    "print(f\"SVHN Train Size: {len(svhn_train)}\")\n",
    "print(f\"SVHN Test Size: {len(svhn_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Train Subset Size: 10000\n",
      "MNIST Test Subset Size: 5000\n",
      "USPS Train Subset Size: 5000\n",
      "USPS Test Subset Size: 1000\n",
      "SVHN Train Subset Size: 10000\n",
      "SVHN Test Subset Size: 5000\n"
     ]
    }
   ],
   "source": [
    "# Function to create a subset\n",
    "def create_subset(dataset, subset_size, seed=42):\n",
    "    \"\"\"\n",
    "    Creates a random subset of the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (Dataset): The original dataset.\n",
    "        subset_size (int): The number of samples in the subset.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        Subset: A PyTorch Subset object.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    indices = random.sample(range(len(dataset)), subset_size)\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "# Create subsets of the train and test datasets\n",
    "mnist_train_subset = create_subset(mnist_train, 10000)\n",
    "mnist_test_subset = create_subset(mnist_test, 5000)\n",
    "usps_train_subset = create_subset(usps_train, 5000)\n",
    "usps_test_subset = create_subset(usps_test, 1000)\n",
    "svhn_train_subset = create_subset(svhn_train, 10000)\n",
    "svhn_test_subset = create_subset(svhn_test, 5000)\n",
    "\n",
    "# Creating the subset dataloaders\n",
    "mnist_train_subset_loader = DataLoader(mnist_train_subset, batch_size=batch_size, shuffle=True)\n",
    "mnist_test_subset_loader = DataLoader(mnist_test_subset, batch_size=batch_size, shuffle=False)\n",
    "usps_train_subset_loader = DataLoader(usps_train_subset, batch_size=batch_size, shuffle=True)\n",
    "usps_test_subset_loader = DataLoader(usps_test_subset, batch_size=batch_size, shuffle=False)\n",
    "svhn_train_subset_loader = DataLoader(svhn_train_subset, batch_size=batch_size, shuffle=True)\n",
    "svhn_test_subset_loader = DataLoader(svhn_test_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Check the size of the subsets\n",
    "print(f\"MNIST Train Subset Size: {len(mnist_train_subset)}\")\n",
    "print(f\"MNIST Test Subset Size: {len(mnist_test_subset)}\")\n",
    "print(f\"USPS Train Subset Size: {len(usps_train_subset)}\")\n",
    "print(f\"USPS Test Subset Size: {len(usps_test_subset)}\")\n",
    "print(f\"SVHN Train Subset Size: {len(svhn_train_subset)}\")\n",
    "print(f\"SVHN Test Subset Size: {len(svhn_test_subset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DANN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseLayerF(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "        return output, None\n",
    "\n",
    "def optimizer_scheduler(optimizer, p):\n",
    "    \"\"\"\n",
    "    Adjust the learning rate of optimizer\n",
    "    :param optimizer: optimizer for updating parameters\n",
    "    :param p: a variable for adjusting learning rate\n",
    "    :return: optimizer\n",
    "    \"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = 0.01 / (1. + 10 * p) ** 0.75\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DANN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: torch.Size([64, 2048])\n",
      "Class output shape: torch.Size([64, 31])\n",
      "Domain output shape: torch.Size([64, 2])\n"
     ]
    }
   ],
   "source": [
    "# class DANN(nn.Module):\n",
    "#     def __init__(self, num_classes, alpha=1.0):\n",
    "#         super(DANN, self).__init__()\n",
    "#         self.alpha = alpha\n",
    "#         self.feature_extractor = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "#         num_features = self.feature_extractor.fc.in_features\n",
    "#         self.feature_extractor.fc = nn.Identity()\n",
    "#         self.class_classifier = nn.Sequential(\n",
    "#             nn.Linear(num_features, 512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(512, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(256, num_classes)\n",
    "#         )\n",
    "#         self.domain_classifier = nn.Sequential(\n",
    "#             nn.Linear(num_features, 512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(512, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(256, 1)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x, alpha=None):\n",
    "#         if alpha is None:\n",
    "#             alpha = self.alpha\n",
    "#         features = self.feature_extractor(x)\n",
    "#         reverse_features = ReverseLayerF.apply(features, alpha)\n",
    "#         class_output = self.class_classifier(features)\n",
    "#         domain_output = self.domain_classifier(reverse_features)\n",
    "#         return class_output, domain_output\n",
    "\n",
    "\n",
    "# # Create the model\n",
    "# num_classes = 31\n",
    "# model = DANN(num_classes, 1.0).to(device)\n",
    "# summary(model, input_size=(64, 3, 224, 224))\n",
    "\n",
    "class Extractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Extractor, self).__init__()\n",
    "        self.feature_extractor = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "        num_features = self.feature_extractor.fc.in_features\n",
    "        self.feature_extractor.fc = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        return features\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.class_classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        class_output = self.class_classifier(x)\n",
    "        return class_output\n",
    "\n",
    "class DomainClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DomainClassifier, self).__init__()\n",
    "        self.domain_classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, alpha):\n",
    "        reversed_input = ReverseLayerF.apply(x, alpha)\n",
    "        domain_output = self.domain_classifier(reversed_input)\n",
    "        return domain_output\n",
    "\n",
    "# Testing the flow of the model\n",
    "extractor = Extractor().to(device)\n",
    "classifier = Classifier(31).to(device)\n",
    "domain_classifier = DomainClassifier().to(device)\n",
    "\n",
    "# Testing the flow of the model\n",
    "x = torch.randn(64, 3, 224, 224).to(device)\n",
    "features = extractor(x)\n",
    "print(\"Feature shape:\", features.shape)\n",
    "\n",
    "class_output = classifier(features)\n",
    "print(\"Class output shape:\", class_output.shape)\n",
    "\n",
    "domain_output = domain_classifier(features, 1.0)\n",
    "print(\"Domain output shape:\", domain_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the training and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_dann_model(model, source_loader, target_loader, num_epochs, loss_class, loss_domain, optimizer, source_name, target_name, device):\n",
    "#     model.train()\n",
    "#     for epoch in range(num_epochs):\n",
    "#         total_loss = 0.0\n",
    "#         correct_class = 0\n",
    "#         correct_domain = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         source_iter = iter(source_loader)\n",
    "#         target_iter = iter(target_loader)\n",
    "#         num_batches = min(len(source_iter), len(target_iter))\n",
    "\n",
    "#         with tqdm(total=num_batches, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as pbar:\n",
    "#             for _ in range(num_batches):\n",
    "#                 source_data, source_labels = next(source_iter)\n",
    "#                 target_data, _ = next(target_iter)\n",
    "\n",
    "#                 source_data, source_labels = source_data.to(device), source_labels.to(device)\n",
    "#                 target_data = target_data.to(device)\n",
    "\n",
    "#                 optimizer.zero_grad()\n",
    "\n",
    "#                 # Forward pass\n",
    "#                 class_output, domain_output = model(source_data)\n",
    "#                 _, target_domain_output = model(target_data)\n",
    "\n",
    "#                 # Compute losses\n",
    "#                 loss_s_label = loss_class(class_output, source_labels)\n",
    "#                 loss_s_domain = loss_domain(domain_output, torch.zeros_like(domain_output))\n",
    "#                 loss_t_domain = loss_domain(target_domain_output, torch.ones_like(target_domain_output))\n",
    "\n",
    "#                 loss = loss_s_label + loss_s_domain + loss_t_domain\n",
    "#                 total_loss += loss.item()\n",
    "\n",
    "#                 # Backward pass and optimization\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "\n",
    "#                 # Compute accuracies\n",
    "#                 _, predicted_class = torch.max(class_output, 1)\n",
    "#                 correct_class += (predicted_class == source_labels).sum().item()\n",
    "\n",
    "#                 _, predicted_domain = torch.max(domain_output, 1)\n",
    "#                 correct_domain += (predicted_domain == torch.zeros_like(domain_output)).sum().item()\n",
    "\n",
    "#                 _, predicted_target_domain = torch.max(target_domain_output, 1)\n",
    "#                 correct_domain += (predicted_target_domain == torch.ones_like(target_domain_output)).sum().item()\n",
    "\n",
    "#                 total_samples += source_labels.size(0)\n",
    "\n",
    "#                 pbar.set_postfix(loss=total_loss / total_samples, class_acc=correct_class / total_samples, domain_acc=correct_domain / (2 * total_samples))\n",
    "#                 pbar.update(1)\n",
    "\n",
    "#         print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/total_samples:.4f}, Class Accuracy: {correct_class/total_samples:.4f}, Domain Accuracy: {correct_domain/(2*total_samples):.4f}\")\n",
    "\n",
    "def tester(encoder, classifier, discriminator, source_test_loader, target_test_loader, training_mode, device):\n",
    "    encoder.to(device)\n",
    "    classifier.to(device)\n",
    "    \n",
    "    # Set models to eval mode\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "    # discriminator.eval()\n",
    "\n",
    "    if training_mode == 'DANN':\n",
    "        discriminator.to(device)\n",
    "        discriminator.eval()\n",
    "        domain_correct = 0\n",
    "\n",
    "    source_correct = 0\n",
    "    target_correct = 0\n",
    "\n",
    "    for batch_idx, (source_data, target_data) in enumerate(zip(source_test_loader, target_test_loader)):\n",
    "        p = float(batch_idx) / len(source_test_loader)\n",
    "        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "\n",
    "        # Process source and target data\n",
    "        source_image, source_label = source_image.to(device), source_label.to(device)\n",
    "        target_image, target_label = target_image.to(device), target_label.to(device)\n",
    "\n",
    "        # Compute source and target predictions\n",
    "        source_pred = compute_output(encoder, classifier, source_image, alpha=None)\n",
    "        target_pred = compute_output(encoder, classifier, target_image, alpha=None)\n",
    "\n",
    "        # Update correct counts\n",
    "        source_correct += source_pred.eq(source_label.data.view_as(source_pred)).sum().item()\n",
    "        target_correct += target_pred.eq(target_label.data.view_as(target_pred)).sum().item()\n",
    "\n",
    "        if training_mode == 'DANN':\n",
    "            # Process combined images for domain classification\n",
    "            combined_image = torch.cat((source_image, target_image), 0)\n",
    "            domain_labels = torch.cat((torch.zeros(source_label.size(0), dtype=torch.long),\n",
    "                                       torch.ones(target_label.size(0), dtype=torch.long)), 0).cuda()\n",
    "\n",
    "            # Compute domain predictions\n",
    "            domain_pred = compute_output(encoder, discriminator, combined_image, alpha=alpha)\n",
    "            domain_correct += domain_pred.eq(domain_labels.data.view_as(domain_pred)).sum().item()\n",
    "\n",
    "    source_dataset_len = len(source_test_loader.dataset)\n",
    "    target_dataset_len = len(target_test_loader.dataset)\n",
    "\n",
    "    accuracies = {\n",
    "        \"Source\": {\n",
    "            \"correct\": source_correct,\n",
    "            \"total\": source_dataset_len,\n",
    "            \"accuracy\": calculate_accuracy(source_correct, source_dataset_len)\n",
    "        },\n",
    "        \"Target\": {\n",
    "            \"correct\": target_correct,\n",
    "            \"total\": target_dataset_len,\n",
    "            \"accuracy\": calculate_accuracy(target_correct, target_dataset_len)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if training_mode == 'DANN':\n",
    "        accuracies[\"Domain\"] = {\n",
    "            \"correct\": domain_correct,\n",
    "            \"total\": source_dataset_len + target_dataset_len,\n",
    "            \"accuracy\": calculate_accuracy(domain_correct, source_dataset_len + target_dataset_len)\n",
    "        }\n",
    "\n",
    "    print_accuracy(training_mode, accuracies)\n",
    "\n",
    "def compute_output(encoder, classifier, images, alpha=None):\n",
    "    features = encoder(images)\n",
    "    if isinstance(classifier, DomainClassifier):\n",
    "        outputs = classifier(features, alpha)  # Domain classifier\n",
    "    else:\n",
    "        outputs = classifier(features)  # Category classifier\n",
    "    preds = outputs.data.max(1, keepdim=True)[1]\n",
    "    return preds\n",
    "\n",
    "\n",
    "def calculate_accuracy(correct, total):\n",
    "    return 100. * correct / total\n",
    "\n",
    "\n",
    "def print_accuracy(training_mode, accuracies):\n",
    "    print(f\"Test Results on {training_mode}:\")\n",
    "    for key, value in accuracies.items():\n",
    "        print(f\"{key} Accuracy: {value['correct']}/{value['total']} ({value['accuracy']:.2f}%)\")\n",
    "\n",
    "def train_dann(encoder, classifier, discriminator, source_train_loader, target_train_loader, epochs, device):\n",
    "    print(\"Training with the DANN adaptation method\")\n",
    "\n",
    "    classifier_criterion = nn.CrossEntropyLoss().to(device)\n",
    "    discriminator_criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        list(encoder.parameters()) +\n",
    "        list(classifier.parameters()) +\n",
    "        list(discriminator.parameters()),\n",
    "        lr=0.01,\n",
    "        momentum=0.9)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        # Setting the models to train mode\n",
    "        encoder.train()\n",
    "        classifier.train()\n",
    "        discriminator.train()\n",
    "\n",
    "        start_steps = epoch * len(source_train_loader)\n",
    "        total_steps = epochs * len(target_train_loader)\n",
    "\n",
    "        for batch_idx, (source_data, target_data) in enumerate(zip(source_train_loader, target_train_loader)):\n",
    "\n",
    "            source_image, source_label = source_data\n",
    "            target_image, target_label = target_data\n",
    "\n",
    "            p = float(batch_idx + start_steps) / total_steps\n",
    "            alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "\n",
    "            # source_image = torch.cat((source_image, source_image, source_image), 1)\n",
    "\n",
    "            source_image, source_label = source_image.to(device), source_label.to(device)\n",
    "            target_image, target_label = target_image.to(device), target_label.to(device)\n",
    "\n",
    "            print(f\"Source image shape: {source_image.shape}\")\n",
    "            print(f\"Target image shape: {target_image.shape}\")\n",
    "\n",
    "            combined_image = torch.cat((source_image, target_image), 0)\n",
    "\n",
    "            optimizer = optimizer_scheduler(optimizer=optimizer, p=p)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            combined_feature = encoder(combined_image)\n",
    "            source_feature = encoder(source_image)\n",
    "\n",
    "            # 1.Classification loss\n",
    "            class_pred = classifier(source_feature)\n",
    "            class_loss = classifier_criterion(class_pred, source_label)\n",
    "\n",
    "            # 2. Domain loss\n",
    "            domain_pred = discriminator(combined_feature, alpha)\n",
    "\n",
    "            domain_source_labels = torch.zeros(source_label.shape[0]).type(torch.LongTensor)\n",
    "            domain_target_labels = torch.ones(target_label.shape[0]).type(torch.LongTensor)\n",
    "            domain_combined_label = torch.cat((domain_source_labels, domain_target_labels), 0).cuda()\n",
    "            domain_loss = discriminator_criterion(domain_pred, domain_combined_label)\n",
    "\n",
    "            total_loss = class_loss + domain_loss\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                print('[{}/{} ({:.0f}%)]\\tTotal Loss: {:.4f}\\tClassification Loss: {:.4f}\\tDomain Loss: {:.4f}'.format(\n",
    "                    batch_idx * len(target_image), len(target_train_loader.dataset), 100. * batch_idx / len(target_train_loader), total_loss.item(), class_loss.item(), domain_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels in Amazon dataset: 31\n",
      "Training with the DANN adaptation method\n",
      "Epoch: 0\n",
      "Source image shape: torch.Size([64, 3, 224, 224])\n",
      "Target image shape: torch.Size([64, 3, 224, 224])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "amazon_loader = load_data(data_path, 'amazon', 64, 'src')\n",
    "webcam_loader = load_data(data_path, 'webcam', 64, 'tar')\n",
    "\n",
    "print(\"Number of labels in Amazon dataset:\", len(amazon_loader.dataset.classes))\n",
    "\n",
    "# Create the model\n",
    "encoder = Extractor().to(device)\n",
    "classifier = Classifier(31).to(device)\n",
    "discriminator = DomainClassifier().to(device)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "# train_dann_model(model, amazon_loader, webcam_loader, 10, loss_class, loss_domain, optimizer, \"amazon\", \"webcam\", device)\n",
    "# train_dann_model(model, amazon_loader, webcam_loader, 5, loss_class, loss_domain, optimizer, \"amazon\", \"webcam\", device)\n",
    "train_dann(encoder, classifier, discriminator, amazon_loader, webcam_loader, 5, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
